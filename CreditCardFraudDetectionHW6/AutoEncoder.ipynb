{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./archive/creditcard.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n",
      "----------------------------------------------\n",
      "0    99.827251\n",
      "1     0.172749\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['Class'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['Class'].value_counts(normalize=True) * 100)\n",
    "df = df.drop('Time', axis=1)\n",
    "df_pos = df[df['Class'] == 0]\n",
    "df_pos = df_pos.sample(frac=1)\n",
    "df_neg = df[df['Class'] == 1]\n",
    "df_neg = df_neg.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inbalance, Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "DATA_SPLIT_RATE = 0.8\n",
    "COPY = int(len(df_pos) / len(df_neg))\n",
    "\n",
    "pos_split = int(len(df_pos) * DATA_SPLIT_RATE // 1)\n",
    "train_pos = df_pos[:pos_split]\n",
    "test_pos = df_pos[pos_split:]\n",
    "\n",
    "neg_split = int(len(df_neg) * DATA_SPLIT_RATE // 1)\n",
    "train_neg = df_neg[:neg_split]\n",
    "test_neg = df_neg[neg_split:]\n",
    "\n",
    "train_neg_ = train_neg.copy()\n",
    "\n",
    "for i in range(COPY):\n",
    "    train_neg = pd.concat([train_neg, train_neg_], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454606\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_all = pd.concat([train_pos, train_neg], ignore_index=True)\n",
    "df_all = df_all.sample(frac=1)\n",
    "df_all.reset_index(drop=True, inplace=True)\n",
    "sns.displot(df_all['Class'])\n",
    "print(len(df_all))\n",
    "df_all_ = df_all.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.tensor(df_all_.values.astype(np.float32))\n",
    "target = torch.tensor(df_all['Class'].values.astype(np.float32))\n",
    "train_set = torch.utils.data.TensorDataset(train, target)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Linear(29, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.Linear(16, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 29),\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        codes = self.Encoder(inputs)\n",
    "        decoded = self.Decoder(codes)\n",
    "        return codes, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classification, self).__init__()\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Linear(16, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(16, 2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.FC(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoEncoder().to(device)\n",
    "\n",
    "Cmodel = Classification().to(device)\n",
    "\n",
    "LR = 3e-4\n",
    "Epoch = 10\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7104/7104 [00:29<00:00, 240.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] Loss: 1.0394210815429688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7104/7104 [00:29<00:00, 243.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/10] Loss: 0.5862821936607361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7104/7104 [00:28<00:00, 245.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/10] Loss: 0.4080249071121216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7104/7104 [00:28<00:00, 247.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/10] Loss: 0.3291270136833191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7104/7104 [00:28<00:00, 247.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/10] Loss: 0.2935461401939392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7104/7104 [00:28<00:00, 248.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/10] Loss: 0.4079771935939789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7104/7104 [00:28<00:00, 247.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/10] Loss: 0.7964762449264526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7104/7104 [00:29<00:00, 243.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/10] Loss: 0.8698421120643616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7104/7104 [00:28<00:00, 244.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/10] Loss: 0.25812914967536926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7104/7104 [00:28<00:00, 246.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/10] Loss: 0.1578819304704666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i in range(Epoch):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for idx, data in enumerate(tqdm(train_loader)):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        codes, decoded = model(inputs)\n",
    "        \n",
    "        loss = criterion(decoded, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Show progress\n",
    "    print('[{}/{}] Loss:'.format(i+1, Epoch), loss.item())\n",
    "# Save\n",
    "torch.save(model, 'autoencoder.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.concat([test_pos, test_neg], ignore_index=True)\n",
    "test_set = test_set.sample(frac=1)\n",
    "test_set.reset_index(drop=True, inplace=True)\n",
    "test_ = test_set.drop('Class', axis=1)\n",
    "test_ = torch.tensor(test_.values.astype(np.float32))\n",
    "target = test_set['Class']\n",
    "target = torch.tensor(target.values.astype(np.float32))\n",
    "\n",
    "test = torch.utils.data.TensorDataset(test_, target)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 891/891 [00:00<00:00, 1090.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(tqdm(test_loader)):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        codes, decoded = model(inputs)\n",
    "        loss = criterion(inputs, decoded)\n",
    "        test_loss += loss.item()\n",
    "        total += labels.size(0)\n",
    "    print('Testing loss: %.3f'%(test_loss / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74ea91778db1d856ff87590d1dff4d6dab0747003a22ee1eca989cea41e9e8d4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
