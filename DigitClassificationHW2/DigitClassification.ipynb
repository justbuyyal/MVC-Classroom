{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Library"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torchvision\r\n",
    "from torchvision import datasets,transforms\r\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "import random\r\n",
    "from collections import OrderedDict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "path = './digit-recognizer/'\r\n",
    "test_data = pd.read_csv(path+'test.csv')\r\n",
    "train_data = pd.read_csv(path+'train.csv')\r\n",
    "# Ground Truth of training data\r\n",
    "groundtruth = np.array(train_data['label'])\r\n",
    "train_data = train_data.drop(['label'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Transfer dataframe to np array\r\n",
    "train_set = np.array(train_data)\r\n",
    "test_set = np.array(test_data)\r\n",
    "# Reshape of np array to matrix form [1*28*28] for each black-white image\r\n",
    "train_set = np.reshape(train_set, [train_set.shape[0], 1, 28, 28])\r\n",
    "test_set = np.reshape(test_set, [test_set.shape[0], 1, 28, 28])\r\n",
    "print(train_set.shape)\r\n",
    "print(test_set.shape)\r\n",
    "# Data Normalization\r\n",
    "nor_train = np.linalg.norm(train_set)\r\n",
    "train_set = train_set / nor_train\r\n",
    "nor_test = np.linalg.norm(test_set)\r\n",
    "test_set = test_set / nor_test\r\n",
    "# Split training data into train_set and val_set 4:1 using 5-Fold Cross Validation\r\n",
    "k = 5\r\n",
    "epoch = 100\r\n",
    "batch_size = 64\r\n",
    "splits = KFold(n_splits=k, shuffle=True, random_state=35)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(42000, 1, 28, 28)\n",
      "(28000, 1, 28, 28)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Building my own dataset\r\n",
    "class digitDataset(Dataset):\r\n",
    "    def __init__(self, x, y=None):\r\n",
    "        self.data = torch.from_numpy(x).float()\r\n",
    "        if y is not None:\r\n",
    "            y = y.astype(int)\r\n",
    "            self.label = torch.LongTensor(y)\r\n",
    "        else: self.label = None\r\n",
    "    def __getitem__(self, index):\r\n",
    "        if self.label is not None:\r\n",
    "            return self.data[index], self.label[index]\r\n",
    "        else: return self.data[index]\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN Model Architecture"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Loss Function\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "# Checking using device\r\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "# Dictionary for saving each fold's train and val loss\r\n",
    "foldperf = {}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "class CNNModel(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(CNNModel, self).__init__()\r\n",
    "        self.CNN_layer = nn.Sequential(\r\n",
    "            nn.Conv2d(in_channels= 1, out_channels= 64, kernel_size= 3, stride= 1, padding= 1),\r\n",
    "            nn.BatchNorm2d(64),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.Conv2d(in_channels= 64, out_channels= 64, kernel_size= 3, stride= 1, padding= 1),\r\n",
    "            nn.BatchNorm2d(64),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.MaxPool2d(2),\r\n",
    "\r\n",
    "            nn.Conv2d(in_channels= 64, out_channels= 96, kernel_size= 3, stride= 1, padding= 1),\r\n",
    "            nn.BatchNorm2d(96),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.Conv2d(in_channels= 96, out_channels= 64, kernel_size= 3, stride= 1, padding= 1),\r\n",
    "            nn.BatchNorm2d(64),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.Conv2d(in_channels= 64, out_channels= 96, kernel_size= 3, stride= 1, padding= 1),\r\n",
    "            nn.BatchNorm2d(96),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.MaxPool2d(2),\r\n",
    "\r\n",
    "            nn.Conv2d(in_channels= 96, out_channels= 128, kernel_size= 3, stride= 1, padding= 1),\r\n",
    "            nn.BatchNorm2d(128),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.Conv2d(in_channels= 128, out_channels= 96, kernel_size= 3, stride= 1, padding= 1),\r\n",
    "            nn.BatchNorm2d(96),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.Conv2d(in_channels= 96, out_channels= 128, kernel_size= 3, stride= 1, padding= 1),\r\n",
    "            nn.BatchNorm2d(128),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.MaxPool2d(2),\r\n",
    "\r\n",
    "            nn.Conv2d(in_channels= 128, out_channels= 256, kernel_size= 3, stride= 1, padding= 1),\r\n",
    "            nn.BatchNorm2d(256),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.Conv2d(in_channels= 256, out_channels= 192, kernel_size= 3, stride= 1, padding= 1),\r\n",
    "            nn.BatchNorm2d(192),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.Conv2d(in_channels= 192, out_channels= 256, kernel_size= 3, stride= 1, padding= 1),\r\n",
    "            nn.BatchNorm2d(256),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.MaxPool2d(2),\r\n",
    "\r\n",
    "            nn.Conv2d(in_channels= 256, out_channels= 448, kernel_size= 3, stride= 1, padding= 1),\r\n",
    "            nn.BatchNorm2d(448),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.Conv2d(in_channels= 448, out_channels= 256, kernel_size= 3, stride= 1, padding= 1),\r\n",
    "            nn.BatchNorm2d(256),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.Conv2d(in_channels= 256, out_channels= 448, kernel_size= 3, stride= 1, padding= 1),\r\n",
    "            nn.BatchNorm2d(448),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.MaxPool2d(2),\r\n",
    "            nn.Flatten()\r\n",
    "        )\r\n",
    "        self.FC_layer = nn.Sequential(\r\n",
    "            nn.Linear(448, 10),\r\n",
    "            nn.Softmax()\r\n",
    "        )\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.CNN_layer(x)\r\n",
    "        x = self.FC_layer(x)\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torchsummary import summary\r\n",
    "\r\n",
    "test_model = CNNModel()\r\n",
    "summary(test_model, (1, 28, 28), device=\"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K Fold Cross Validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "def train_epoch(model, device, dataloader, loss_fn, optimizer):\r\n",
    "    train_loss, train_correct = 0.0, 0\r\n",
    "    model.train()\r\n",
    "    for images, labels in dataloader:\r\n",
    "        images, labels = images.to(device), labels.to(device)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        output = model(images)\r\n",
    "        loss = loss_fn(output, labels)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        train_loss += loss.item() * images.size(0)\r\n",
    "        scores, predictions = torch.max(output.data, 1)\r\n",
    "        train_correct += (predictions == labels).sum().item()\r\n",
    "    return train_loss, train_correct"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "def valid_epoch(model, device, dataloader, loss_fn):\r\n",
    "    valid_loss, val_correct = 0.0, 0\r\n",
    "    model.eval()\r\n",
    "    for images, labels in dataloader:\r\n",
    "        images, labels = images.to(device), labels.to(device)\r\n",
    "        output = model(images)\r\n",
    "        loss = loss_fn(output, labels)\r\n",
    "        valid_loss += loss.item() * images.size(0)\r\n",
    "        scores, predictions = torch.max(output.data, 1)\r\n",
    "        val_correct += (predictions == labels).sum().item()\r\n",
    "    return valid_loss, val_correct"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(train_set.shape[0]))):\r\n",
    "    print('Fold {}'.format(fold + 1))\r\n",
    "    train_dset = digitDataset(train_set, groundtruth)\r\n",
    "    train_loader = DataLoader(train_dset, batch_size=batch_size, sampler=train_idx)\r\n",
    "    val_loader = DataLoader(train_dset, batch_size=batch_size, sampler=val_idx)\r\n",
    "    \r\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "    \r\n",
    "    model =CNNModel()\r\n",
    "    model.to(device)\r\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\r\n",
    "\r\n",
    "    history = {'train_loss': [], 'val_loss': [],'train_acc':[],'val_acc':[]}\r\n",
    "\r\n",
    "    for epoch in range(epoch):\r\n",
    "        train_loss, train_correct = train_epoch(model, device, train_loader, criterion, optimizer)\r\n",
    "        val_loss, val_correct = valid_epoch(model, device, val_loader, criterion)\r\n",
    "\r\n",
    "        train_loss = train_loss / len(train_loader.sampler)\r\n",
    "        train_acc = train_correct / len(train_loader.sampler) * 100\r\n",
    "        val_loss = val_loss / len(val_loader.sampler)\r\n",
    "        val_acc = val_correct / len(val_loader.sampler) * 100\r\n",
    "\r\n",
    "        print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Validae Loss:{:.3f} AVG Training Acc {:.2f} % AVG Validate Acc {:.2f} %\".format(epoch + 1,\r\n",
    "                                                                                                             epoch,\r\n",
    "                                                                                                             train_loss,\r\n",
    "                                                                                                             val_loss,\r\n",
    "                                                                                                             train_acc,\r\n",
    "                                                                                                             val_acc))\r\n",
    "        history['train_loss'].append(train_loss)\r\n",
    "        history['val_loss'].append(val_loss)\r\n",
    "        history['train_acc'].append(train_acc)\r\n",
    "        history['val_acc'].append(val_acc)\r\n",
    "\r\n",
    "    foldperf['fold{}'.format(fold+1)] = history  \r\n",
    "\r\n",
    "torch.save(model,'k_cross_CNN.pt')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-e09c74afc973>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-81dbb79b44dc>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, device, dataloader, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-48-0cf95d0a2d52>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m         ]))\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCNN_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFC_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "interpreter": {
   "hash": "74ea91778db1d856ff87590d1dff4d6dab0747003a22ee1eca989cea41e9e8d4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}