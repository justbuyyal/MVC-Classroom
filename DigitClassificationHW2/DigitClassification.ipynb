{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Library"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torchvision\r\n",
    "from torchvision import datasets,transforms\r\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "import random\r\n",
    "from collections import OrderedDict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "path = './digit-recognizer/'\r\n",
    "test_data = pd.read_csv(path+'test.csv')\r\n",
    "train_data = pd.read_csv(path+'train.csv')\r\n",
    "# Ground Truth of training data\r\n",
    "groundtruth = np.array(train_data['label'])\r\n",
    "train_data = train_data.drop(['label'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Transfer dataframe to np array\r\n",
    "train_set = np.array(train_data)\r\n",
    "test_set = np.array(test_data)\r\n",
    "# Reshape of np array to matrix form [1*28*28] for each black-white image\r\n",
    "train_set = np.reshape(train_set, [train_set.shape[0], 1, 28, 28])\r\n",
    "test_set = np.reshape(test_set, [test_set.shape[0], 1, 28, 28])\r\n",
    "print(train_set.shape)\r\n",
    "print(test_set.shape)\r\n",
    "# Data Normalization\r\n",
    "nor_train = np.linalg.norm(train_set)\r\n",
    "train_set = train_set / nor_train\r\n",
    "nor_test = np.linalg.norm(test_set)\r\n",
    "test_set = test_set / nor_test\r\n",
    "# Split training data into train_set and val_set 4:1 using 5-Fold Cross Validation\r\n",
    "k = 5\r\n",
    "epoch = 100\r\n",
    "batch_size = 64\r\n",
    "splits = KFold(n_splits=k, shuffle=True, random_state=35)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(42000, 1, 28, 28)\n",
      "(28000, 1, 28, 28)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Building my own dataset\r\n",
    "class digitDataset(Dataset):\r\n",
    "    def __init__(self, x, y=None):\r\n",
    "        self.data = torch.from_numpy(x).float()\r\n",
    "        if y is not None:\r\n",
    "            y = y.astype(int)\r\n",
    "            self.label = torch.LongTensor(y)\r\n",
    "        else: self.label = None\r\n",
    "    def __getitem__(self, index):\r\n",
    "        if self.label is not None:\r\n",
    "            return self.data[index], self.label[index]\r\n",
    "        else: return self.data[index]\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN Model Architecture"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Loss Function\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "# Checking using device\r\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "# Dictionary for saving each fold's train and val loss\r\n",
    "foldperf = {}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "class CNNModel(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(CNNModel, self).__init__()\r\n",
    "        self.CNN_layer = nn.Sequential(\r\n",
    "            nn.Conv2d(1, 64, 3, 1, 1),\r\n",
    "            nn.BatchNorm2d(64),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.Conv2d(64, 64, 3, 1, 1),\r\n",
    "            nn.BatchNorm2d(64),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.MaxPool2d(2),\r\n",
    "\r\n",
    "            nn.Conv2d(64, 256, 3, 1, 1),\r\n",
    "            nn.BatchNorm2d(256),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\r\n",
    "            nn.BatchNorm2d(256),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.MaxPool2d(2),\r\n",
    "\r\n",
    "            nn.Conv2d(256, 512, 3, 1, 1),\r\n",
    "            nn.BatchNorm2d(512),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.Conv2d(512, 128, 2, 1, 1),\r\n",
    "            nn.BatchNorm2d(128),\r\n",
    "            nn.LeakyReLU(),\r\n",
    "            nn.MaxPool2d(2),\r\n",
    "            nn.Flatten()\r\n",
    "        )\r\n",
    "        self.FC_layer = nn.Sequential(\r\n",
    "            nn.Linear(2048, 10),\r\n",
    "            nn.Softmax()\r\n",
    "        )\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.CNN_layer(x)\r\n",
    "        x = self.FC_layer(x)\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "from torchsummary import summary\r\n",
    "\r\n",
    "test_model = CNNModel()\r\n",
    "summary(test_model, (1, 28, 28), device=\"cpu\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]             640\n",
      "       BatchNorm2d-2           [-1, 64, 28, 28]             128\n",
      "         LeakyReLU-3           [-1, 64, 28, 28]               0\n",
      "            Conv2d-4           [-1, 64, 28, 28]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 28, 28]             128\n",
      "         LeakyReLU-6           [-1, 64, 28, 28]               0\n",
      "         MaxPool2d-7           [-1, 64, 14, 14]               0\n",
      "            Conv2d-8          [-1, 256, 14, 14]         147,712\n",
      "       BatchNorm2d-9          [-1, 256, 14, 14]             512\n",
      "        LeakyReLU-10          [-1, 256, 14, 14]               0\n",
      "           Conv2d-11          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-12          [-1, 256, 14, 14]             512\n",
      "        LeakyReLU-13          [-1, 256, 14, 14]               0\n",
      "        MaxPool2d-14            [-1, 256, 7, 7]               0\n",
      "           Conv2d-15            [-1, 512, 7, 7]       1,180,160\n",
      "      BatchNorm2d-16            [-1, 512, 7, 7]           1,024\n",
      "        LeakyReLU-17            [-1, 512, 7, 7]               0\n",
      "           Conv2d-18            [-1, 128, 8, 8]         262,272\n",
      "      BatchNorm2d-19            [-1, 128, 8, 8]             256\n",
      "        LeakyReLU-20            [-1, 128, 8, 8]               0\n",
      "        MaxPool2d-21            [-1, 128, 4, 4]               0\n",
      "          Flatten-22                 [-1, 2048]               0\n",
      "           Linear-23                   [-1, 10]          20,490\n",
      "          Softmax-24                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 2,240,842\n",
      "Trainable params: 2,240,842\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 5.58\n",
      "Params size (MB): 8.55\n",
      "Estimated Total Size (MB): 14.13\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\wen19\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\nn\\modules\\container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K Fold Cross Validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "def train_epoch(model, device, dataloader, loss_fn, optimizer):\r\n",
    "    train_loss, train_correct = 0.0, 0\r\n",
    "    model.train()\r\n",
    "    for images, labels in dataloader:\r\n",
    "        images, labels = images.to(device), labels.to(device)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        output = model(images)\r\n",
    "        loss = loss_fn(output, labels)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        train_loss += loss.item() * images.size(0)\r\n",
    "        scores, predictions = torch.max(output.data, 1)\r\n",
    "        train_correct += (predictions == labels).sum().item()\r\n",
    "    return train_loss, train_correct"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "def valid_epoch(model, device, dataloader, loss_fn):\r\n",
    "    valid_loss, val_correct = 0.0, 0\r\n",
    "    model.eval()\r\n",
    "    for images, labels in dataloader:\r\n",
    "        images, labels = images.to(device), labels.to(device)\r\n",
    "        output = model(images)\r\n",
    "        loss = loss_fn(output, labels)\r\n",
    "        valid_loss += loss.item() * images.size(0)\r\n",
    "        scores, predictions = torch.max(output.data, 1)\r\n",
    "        val_correct += (predictions == labels).sum().item()\r\n",
    "    return valid_loss, val_correct"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(train_set.shape[0]))):\r\n",
    "    print('Fold {}'.format(fold + 1))\r\n",
    "    train_dset = digitDataset(train_set, groundtruth)\r\n",
    "    train_loader = DataLoader(train_dset, batch_size=batch_size, sampler=train_idx)\r\n",
    "    val_loader = DataLoader(train_dset, batch_size=batch_size, sampler=val_idx)\r\n",
    "    \r\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "    \r\n",
    "    model =CNNModel()\r\n",
    "    model.to(device)\r\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\r\n",
    "\r\n",
    "    history = {'train_loss': [], 'val_loss': [],'train_acc':[],'val_acc':[]}\r\n",
    "\r\n",
    "    for epoch in range(epoch):\r\n",
    "        train_loss, train_correct = train_epoch(model, device, train_loader, criterion, optimizer)\r\n",
    "        val_loss, val_correct = valid_epoch(model, device, val_loader, criterion)\r\n",
    "\r\n",
    "        train_loss = train_loss / len(train_loader.sampler)\r\n",
    "        train_acc = train_correct / len(train_loader.sampler) * 100\r\n",
    "        val_loss = val_loss / len(val_loader.sampler)\r\n",
    "        val_acc = val_correct / len(val_loader.sampler) * 100\r\n",
    "\r\n",
    "        print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Validae Loss:{:.3f} AVG Training Acc {:.2f} % AVG Validate Acc {:.2f} %\".format(epoch + 1,\r\n",
    "                                                                                                             epoch,\r\n",
    "                                                                                                             train_loss,\r\n",
    "                                                                                                             val_loss,\r\n",
    "                                                                                                             train_acc,\r\n",
    "                                                                                                             val_acc))\r\n",
    "        history['train_loss'].append(train_loss)\r\n",
    "        history['val_loss'].append(val_loss)\r\n",
    "        history['train_acc'].append(train_acc)\r\n",
    "        history['val_acc'].append(val_acc)\r\n",
    "\r\n",
    "    foldperf['fold{}'.format(fold+1)] = history  \r\n",
    "\r\n",
    "torch.save(model,'k_cross_CNN.pt')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fold 1\n",
      "Epoch:1/0 AVG Training Loss:1.666 AVG Validae Loss:1.523 AVG Training Acc 87.38 % AVG Validate Acc 97.39 %\n",
      "Epoch:2/1 AVG Training Loss:1.507 AVG Validae Loss:1.498 AVG Training Acc 97.96 % AVG Validate Acc 98.32 %\n",
      "Epoch:3/2 AVG Training Loss:1.490 AVG Validae Loss:1.490 AVG Training Acc 98.64 % AVG Validate Acc 98.58 %\n",
      "Epoch:4/3 AVG Training Loss:1.482 AVG Validae Loss:1.485 AVG Training Acc 99.10 % AVG Validate Acc 98.77 %\n",
      "Epoch:5/4 AVG Training Loss:1.477 AVG Validae Loss:1.483 AVG Training Acc 99.34 % AVG Validate Acc 98.79 %\n",
      "Epoch:6/5 AVG Training Loss:1.473 AVG Validae Loss:1.480 AVG Training Acc 99.51 % AVG Validate Acc 98.92 %\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13364/3370350060.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13364/4051182913.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, device, dataloader, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13364/3632439274.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     33\u001b[0m         )\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCNN_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFC_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 440\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "interpreter": {
   "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}